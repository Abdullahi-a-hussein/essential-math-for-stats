{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derivatives\n",
    "\n",
    "Derivatives is used to find the slope of a function at a given point. The slope is useful to measure the rate of change of at the given point in the function\n",
    "\n",
    "In statistics and Machine learning, derivates are useful for execution of certain algorithms such as, gradient descent. When the slope is zero, that means we are at the minimum or the maximum of an output variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.000010000000827\n"
     ]
    }
   ],
   "source": [
    "def derivative_x(f, x, step):\n",
    "    derivtive = (f(x + step) - f(x))/((x + step) - x)\n",
    "    return derivtive\n",
    "\n",
    "\n",
    "def f(x):\n",
    "    return x**2\n",
    "\n",
    "\n",
    "print(derivative_x(f, 2, 0.00001))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Partial Derivatives\n",
    "\n",
    "These derivatives of functions that have multiple input variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Integrals\n",
    "\n",
    "The opposite of derivatives is integral, which finds the area under the curve for a given range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.33\n",
      "1.3333332500000004\n"
     ]
    }
   ],
   "source": [
    "def approximate_integral(a, b, n, f):\n",
    "    delta_x = (b-a)/n\n",
    "    total_sum = 0\n",
    "    for i in range(1, n + 1):\n",
    "        midpoint = a + (i-1) * delta_x + (delta_x/2)\n",
    "        total_sum += f(midpoint) * delta_x\n",
    "    return total_sum\n",
    "\n",
    "def my_function(x):\n",
    "    return x ** 2 + 1\n",
    "\n",
    "\n",
    "area = approximate_integral(a=0, b=1, n=5, f=my_function)\n",
    "print(area)\n",
    "\n",
    "area = approximate_integral(a=0, b=1, n=1000, f=my_function)\n",
    "print(area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probability is how strongly we believe an event will happen, often expressed as a percentage. \n",
    "Probability is about quantifying predictions of events yet to happen, whereas likelihood is measuring the frequency of events that already occurred. \n",
    "\n",
    "In statistics and machine learning, we often use likelihood (the past) in the form of data to predict probability (the future).\n",
    "\n",
    "**The probability of an event happening is strictly between 0.0 and 1.0 inclusive**. That means if $P(x) = 0.7$, then $\\lnot P(X) = 1 - P(X) = 0.3$.\n",
    "\n",
    "This is another distinction between probability and likelihood. Probabilities of all possible mutually exclusive outcomes of an event must sum up to 1.0. Likelihoods, however, are not subject to this rule.\n",
    "\n",
    "Alternatively, probabilities can be expressed as odds $O(X)$ such as $7:3, 7/3$, or $2.\\overline{333}$. \n",
    "\n",
    "To turn an odds $O(X)$ into a proportional probability $P(X)$, use this formula\n",
    "\n",
    "$$\n",
    "P(X) = \\frac{O(X)}{1 + O(X)}\n",
    "$$\n",
    "\n",
    "**Probability vs. Statistics**: Probability is purely theoretical of how likely an event is to happen and does not require data. Statistics, on the other hand, can not exist without data and uses it to discover probability and provides tools to describe data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probability Math\n",
    "The single probability of an event $P(X)$ is called _marginal probability_.\n",
    "\n",
    "##### Joint Probability\n",
    "This is the probability of two or more events occurring simultaneously.\n",
    "A joint probability is used to find the probability of separate events with separate probabilities occurring together.\n",
    "\n",
    "if two events are independents:\n",
    "\n",
    "$$\n",
    "P(A \\text{ and } B) = P(A) \\times P(B)\n",
    "$$\n",
    "\n",
    "The above formula is also called the product rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['H1', 'H2', 'H3', 'H4', 'H5', 'H6', 'T1', 'T2', 'T3', 'T4', 'T5', 'T6'] 12\n"
     ]
    }
   ],
   "source": [
    "# Generate all possible outcomes between a coin toss and die toss.\n",
    "coin = [\"H\", \"T\"]\n",
    "die = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\"]\n",
    "outcomes = [one + two for one in coin for two in die]\n",
    "print(outcomes, len(outcomes)) # the probability of any one outcome is 1/12\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Union Probability\n",
    " This deals with probabilities of one event or another occurring.\n",
    "\n",
    " For mutually exclusive events\n",
    "\n",
    " $$\n",
    " P(A \\text{ or } B) = P(A) + P(B)\n",
    " $$\n",
    "\n",
    " This is also called the addition rule.\n",
    "\n",
    " In general whether events are exclusive or not\n",
    "\n",
    " $$\n",
    " P(A \\text{ or } B) = P(A) + P(B) - P(A \\text{ and } B)\n",
    " $$\n",
    "\n",
    " If $A$ and $B$ are exclusive $P(A \\text{ and } B) = 0$.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conditional Probability and Bayes' Theorem\n",
    "Conditional probability is the probability of an event $A$ occurring given event $B$ has occurred; $P(A \\text{ given } B)$ or $P(A|B)$.\n",
    "\n",
    "##### Bayes' Formula\n",
    "$$\n",
    "P(A|B) = \\frac{P(B|A)\\times P(A)}{P(B)}\n",
    "$$\n",
    "\n",
    "##### Conditional probability and Joint probability\n",
    "$$\n",
    "P(A \\text{ and } B) = P(B) \\times P(A|B) = P(A) \\times P(B|A)\n",
    "$$\n",
    "\n",
    "If event $A$ has no impact on event $B, P(B|A) = P(B)$\n",
    "\n",
    "$$\n",
    "P(A \\text{ or } B) = P(A) + P(B) - P(A|B) \\times P(B)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binomial Distribution\n",
    "Binomial distribution measures how likely $k$ successes can happen out of $n$ trials given $p$ probability.\n",
    "\n",
    "#### Binomial distribution from Scratch\n",
    "The binomial distribution with parameters n and p is the discrete probability distribution of the number of successes in a sequence of n independent experiments, each asking a yes-no question and each with its Boolean-valued outcome: success (with probability p) or failure (with probability q = 1 âˆ’ p).\n",
    "\n",
    "#### Probability mass function of Binomial distribution\n",
    "\n",
    "Given a random variable $X$ such that $X \\sim B(n, p$, the probability of getting exactly $k$ successes is given by the _probability mass function $f(k, n, p)$_:\n",
    "\n",
    "$$\n",
    "f(k, n, p) = P(X=k) =  {n \\choose k}  p^{k}(1 -p)^{n-k}\n",
    "$$\n",
    "\n",
    "for $k = 0, 1, 2, \\cdots, n$, where \n",
    "\n",
    "$$\n",
    "{n \\choose k} = \\frac{n!}{k!(n - k)!}\n",
    "$$\n",
    "\n",
    "is the binomial coefficient.\n",
    "\n",
    "##### Understanding the formula\n",
    "$p^k(1-p)^{n -k}$ is the probability of obtaining a sequence of $n$ independent Bernoulli trials in which $k$ trials are success and the remaining $n-k$ trials are failures. Since the trials are independent with a constant probability of success and a sequence of $n$ such trials has the same probability of being achieved (regardless of the position of success within the sequence).\n",
    "\n",
    "$n\\choose k$ is the number of possible sequence with $k$ successes and $n -k$ failures.\n",
    "\n",
    "The Binomial distribution is concerned with the probability of obtaining  any of these sequence, meaning the probability of obtaining one of them $p^k(1-p)^{n-k}$ must be added $n\\choose k$ times.\n",
    "\n",
    "#### Cumulative Distribution function\n",
    "$$\n",
    "F(k, n, p) = P(X\\le k) = \\sum^{\\lfloor{k}\\rfloor}_{i=0} {n \\choose i} p^i(1 - p)^{n-i}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -> 9.999999999999978e-11\n",
      "1 -> 8.999999999999983e-09\n",
      "2 -> 3.644999999999994e-07\n",
      "3 -> 8.747999999999988e-06\n",
      "4 -> 0.00013778099999999982\n",
      "5 -> 0.0014880347999999986\n",
      "6 -> 0.01116026099999999\n",
      "7 -> 0.057395627999999976\n",
      "8 -> 0.19371024449999993\n",
      "9 -> 0.387420489\n",
      "10 -> 0.3486784401000001\n",
      "probability of getting 8 successes or less:  0.2639010708999999\n"
     ]
    }
   ],
   "source": [
    "#PMF\n",
    "def factorial(n):\n",
    "    product = 1\n",
    "    for i in range(2, n + 1):\n",
    "        product *= i\n",
    "    return product\n",
    "\n",
    "def binomial_coefficient(n, k):\n",
    "    return factorial(n)/(factorial(k) *factorial(n -k)) # n!/(k!(n -k)!)\n",
    "\n",
    "def probability(k, n, p):\n",
    "    return (p**k) * (1 - p)**(n-k)\n",
    "\n",
    "def binomial_pmf(k, n, p):\n",
    "    return binomial_coefficient(n, k) * probability(k, n, p)\n",
    "\n",
    "# Cumulative distribution function\n",
    "def binom_cdf(k, n, p):\n",
    "    cumulative_sum = 0\n",
    "    for i in range(k+1):\n",
    "        cumulative_sum += binomial_pmf(i, n, p)\n",
    "    return cumulative_sum\n",
    "\n",
    "n = 10\n",
    "p = 0.9\n",
    "for k in range(n +1):\n",
    "    print(f\"{k} -> {binomial_pmf(k, n, p)}\")\n",
    "\n",
    "# Probability of getting 8 or less success\n",
    "print(\"probability of getting 8 successes or less: \",binom_cdf(8, n, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beta distribution\n",
    "The _beta distribution allows us to see the likelihood of different underlying probabilities for an event to occur given _alpha_ success and _beta_ failures.\n",
    "\n",
    "#### Beta distribution from scratch\n",
    "The beta distribution has been applied to model the behaviour of random variables limited to intervals of finite length in a wide variety of disciplines. In particular, we are interested in finding how likely is the underlying (and assumed) probability of success of binomial distribution with $\\alpha$ number successes and $\\beta$ failures.\n",
    "\n",
    "##### Probability Density function (PDF)\n",
    "Given $0\\le x \\le 1$ and the shape parameters (in our case, number of successes and number of failures) $\\alpha, \\beta >0$, probability density function is given by the following\n",
    "$$\n",
    "f(x, \\alpha, \\beta) = \\frac{\\Gamma(\\alpha + \\beta)\\times x^{\\alpha - 1}\\times (1 - x)^{\\beta -1}}{\\Gamma(\\alpha)\\times \\Gamma(\\beta)}\n",
    "$$\n",
    "\n",
    "where $\\Gamma(z)$ is the _gamma function_ given $(z-1)!$ for $z\\in\\mathbb{N}$.\n",
    "\n",
    "##### Cumulative Distribution Function (CDF)\n",
    "Suppose we are given the number of successes (8) and the number of failures (2) of 10 Bernoulli trials. We want to determine the probability that the underlying probability of $X\\sim \\text{Binom}(n, p)$ is greater than or equal to $90$%.\n",
    "\n",
    "This means we will need to calculate the under the curve of the pdf function of the beta distribution. \n",
    "\n",
    "This requires integration of the pdf function.  But this is difficult. We can, however, **use Reimann's sum to approximate the integration** \n",
    "\n",
    "We can also use the fact that **the CDF of the beta function is the same as the CDF of the binomial distribution, where $k = \\beta-1, n = \\alpha + \\beta - 1, p = 1 - x$**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The likelihood of the underlying probability equals or less than 90% is:  0.7748412362768455\n",
      "The likelihood of the underlying probability equals or greater than 90% is:  0.22515904881135335\n",
      "0.7748409780000001\n",
      "0.22515902199999993\n"
     ]
    }
   ],
   "source": [
    "# PDF of beta function\n",
    "\n",
    "# factorial calculation\n",
    "def factorial(n):\n",
    "    product = 1\n",
    "    for i in range(2, n + 1):\n",
    "        product *= i\n",
    "    return product\n",
    "\n",
    "def beta_pdf(x, alpha=8, beta=2):\n",
    "    if x < 0:\n",
    "        raise ValueError(\"x must not be zero\")\n",
    "    probability = x**(alpha -1) * (1 - x)**(beta - 1)\n",
    "    constant = factorial(alpha + beta -1)/(factorial(alpha -1) * factorial(beta -1))\n",
    "    return constant * probability\n",
    "\n",
    "# CDF of beta function\n",
    "\n",
    "\n",
    "def reimann_sum_approximation(a, b, n, f):\n",
    "    delta_x = (b - a)/n\n",
    "    total_sum = 0\n",
    "    for i in range(1, n+1):\n",
    "        midpoint = a + (delta_x * (i - 1)) + (delta_x/ 2)\n",
    "        total_sum += f(midpoint) * delta_x\n",
    "    return total_sum\n",
    "\n",
    "# 1: using Reimann Sum approximation\n",
    "beta_cdf11 = reimann_sum_approximation(a=0, b=0.9, n=1_000, f=beta_pdf)\n",
    "beta_cdf12 = reimann_sum_approximation(a=0.9, b=1.0, n=1_000, f=beta_pdf)\n",
    "\n",
    "# 2: Using Binomial distributions CDF\n",
    "beta_cdf21 = binom_cdf(k=2-1, n=10-1, p=1 - 0.9)\n",
    "beta_cdf22 =  1 - binom_cdf(k=2-1, n=10-1, p =1 -0.9)\n",
    "\n",
    "# calculating the likelihood of the underlying probability of the binomial distribution is 90% or less is \n",
    "print(\"The likelihood of the underlying probability equals or less than 90% is: \",beta_cdf11)\n",
    "\n",
    "# calculating the likelihood of the underlying probability of the binomial distribution is 90% or greater is \n",
    "print(\"The likelihood of the underlying probability equals or greater than 90% is: \",beta_cdf12)\n",
    "print(beta_cdf21)\n",
    "print(beta_cdf22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "1. You have 137 passengers booked on a flight from Las Vegas to Dallas. However, you estimate each passenger is 40%  likely to not show up. You are trying to figure out how many seats to over-book so that the plane does not fly empty. How likely is it that at least $50$ passengers will not show up?\n",
    "\n",
    "#### Solution\n",
    "Let's define $k$ as the number of successes (number of people not showing up). $k = 137 * 0.4 = 54.8$\n",
    "and $p$ (probability of success) $0.4$ and $n = 137$\n",
    "\n",
    "$X\\sim \\text{Binom}(k, n, p)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.822095588147425\n"
     ]
    }
   ],
   "source": [
    "# How likely is it that at least $50$ passengers will not show up\n",
    "probabiliyt_50_or_more = 1 - binom_cdf(k=49, n=137, p=0.4) # 1 - (probability of 49 people or less showing up.)\n",
    "print(probabiliyt_50_or_more)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. You flipped a coin 10 times and got heads 8 times and tails 2 times. Do you think this coin has any good probability of being fair? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution\n",
    "We are interested in the question of how likely it is that the coin is fair. That means what is the probability that the underlying probability of the observed binomial outcome is $50$%. \n",
    "Given alpha of $8$ and beta of $2$. We can use Beta distribution to answer.\n",
    "\n",
    "Looking at the answers below we can see The likelihood that the underlying probability is greater or equal to 50% is 98%. It's very unlikely this is a fair coin. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9804695351555468\n",
      "0.019531214843764355\n"
     ]
    }
   ],
   "source": [
    "# The likelihood that the underlying probability is greater or equal to 50%\n",
    "print(reimann_sum_approximation(a=.50, b=1.0, n= 1000, f = beta_pdf))\n",
    "# The likelihood that the underlying probability is less or equal to 50%\n",
    "print(reimann_sum_approximation(a=0, b=0.5, n= 1000, f = beta_pdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptive and inferential statistics\n",
    "\n",
    "Descriptive statistics is used to provide a summary of the data such as the mean, the median, mode, charts, bell curves and other tools used to describe data.\n",
    "\n",
    "Inferential statistics is used to uncover attributes about a larger population based on a sample. \n",
    "\n",
    "**Population** is a particular group of interest we want to study. A **sample** is a subset of the population that is ideally random and unbiased, which we use to infer attributes about the population. \n",
    "\n",
    "##### Types of Biases\n",
    "- _Confirmation bias_ is gathering only data that supports your belief, which can even be done unknowingly.\n",
    "- _Sefl-selection__ bias is when certain types of subjects are more likely to include themselves in the experiment.\n",
    "- _Survival bias_ captures only living and survived subjects, while the deceased ones are never accounted for.\n",
    "\n",
    "#### Descriptive Statistics\n",
    "- *Mean* is the average of a set of values. The mean is calculated the same way for both populations and samples.\n",
    "  - *Sample Mean $\\bar{x}$*\n",
    "  - *Population mean $\\mu$*\n",
    "  - *Weighted mean gives each item a different weight.* This is helpful when we want some values to contribute to the mean more than other.\n",
    "\n",
    "  $$\n",
    "  \\text{weighted mean } = \\frac{(x_1\\cdot w_1) + (x_2\\cdot w_2) + \\ldots + (x_n\\cdot w_n)}{w_1 + w_2 + \\ldots + w_n}\n",
    "  $$\n",
    "\n",
    "- **Median** is the middle most value in a set of ordered values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "# number of pets\n",
    "sample = [0, 1, 5, 7, 9, 10, 14]\n",
    "\n",
    "def median(values):\n",
    "    ordered = sorted(values)\n",
    "    n = len(ordered)\n",
    "    mid = n // 2 - 1 if n % 2 == 0 else n // 2\n",
    "    if n % 2 == 0:\n",
    "        return (ordered[mid] + ordered[mid+1])/2.0\n",
    "    return ordered[mid]\n",
    "print(median(sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The median is a good alternative to the mean when the data is skewed by outliers or values that are extremely large or small compared to the rest of the values. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
